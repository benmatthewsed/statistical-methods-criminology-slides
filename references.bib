@incollection{8347e95e012d4212a5ee429a18ee592e,
  title = {The Collection and Understanding of Administrative Data in {{UK}} Police Forces},
  booktitle = {The Crime Data Handbook},
  author = {Keay, Scott and Towers, Jude},
  editor = {Huey, Laura and {Buil-Gil}, David},
  year = {2024},
  month = apr,
  pages = {227},
  publisher = {Bristol University Press},
  address = {United Kingdom},
  abstract = {In this chapter we explore the potential for administrative data to improve police policy and decision-making by focusing on how to incorporate a critical reflection into the analysis and interpretation of administrative data by understanding its construction. To do this, we focus on Police Recorded Crime (PRC) as the key source of administrative data in policing in England and Wales.We then evaluate where policing is currently in terms of understanding the need for and having the skills to undertake this critical reflection, based on work undertaken with 60 police analysts from the North of England in 2018/19 as part of the N8 Policing Research Partnership. Finally, we look to the future and raise the issue of the place of the police analysts in the policing institution, considering what they currently contribute and what they could contribute to police policy and decision making.},
  isbn = {978-1-5292-3204-2},
  langid = {english}
}

@article{aebiMeasuringInfluenceStatistical,
  title = {9 {{Measuring}} the {{Influence}} of {{Statistical Counting Rules}} on {{Cross-National Differences}} in {{Recorded Crime}}},
  author = {Aebi, Marcelo F},
  langid = {english},
  file = {/home/work/Zotero/storage/2EBJAGPY/Aebi - 9 Measuring the Influence of Statistical Counting .pdf}
}

@incollection{aplinGreyFigureCrime2019,
  title = {The {{Grey Figure}} of {{Crime}}: {{If It Isn}}'t {{Crimed}}, {{It Hasn}}'t {{Happened}}},
  shorttitle = {The {{Grey Figure}} of {{Crime}}},
  booktitle = {Policing {{UK Honour-Based Abuse Crime}}},
  author = {Aplin, Rachael},
  editor = {Aplin, Rachael},
  year = {2019},
  pages = {101--152},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-18430-8_4},
  urldate = {2023-01-11},
  abstract = {Aplin highlights that ``cuffing'' crimes is an enduring discretionary police practice. Sixty-nine per cent of HBA cases (and 89\% of incidents over three years) are not recorded as crimes, despite evidence of criminal offences. In justifying no-crime decisions, officers rely on perceived legalities and formal rules, such as the NCRS requirement for ``victim confirmation'' of crimes, as well as bias and subjective judgement. Performance target pressures and pre-empting CPS no-charge decisions are also explored. Overwhelmingly, findings illustrate that victim reluctance adversely impacts officer's no-crime decisions. Manufacturing victim reluctance is effective in validating police inaction and in officers circumventing perceived ``wasted workload.'' If it is not crimed, it has technically ``not happened,'' which abrogates officers of responsibilities around investigation, prosecution and safeguarding.},
  isbn = {978-3-030-18430-8},
  langid = {english},
  keywords = {Crime recording,Manufactured victim reluctance,Performance targets,Policing honour-based abuse,Threats to kill}
}

@article{atakWesternCrimeDrop2020,
  title = {Beyond the Western Crime Drop: {{Violence}}, Property Offences, and the State in {{Turkey}} 1990--2016},
  shorttitle = {Beyond the Western Crime Drop},
  author = {Atak, K{\i}van{\c c}},
  year = {2020},
  month = mar,
  journal = {International Journal of Law, Crime and Justice},
  volume = {60},
  pages = {100373},
  issn = {1756-0616},
  doi = {10.1016/j.ijlcj.2019.100373},
  urldate = {2023-01-11},
  abstract = {Temporal changes in crime have long attracted scholarly attention. Much research on the recent trajectory of crime rates is dominated by the crime drop thesis in western democracies, with only little input from other societal contexts. The present work offers the first explorative inquiry into a subset violent and property crimes in Turkey over the last quarter-century. Data collected from judicial records, police reports on offences, prison and causes of death statistics are read primarily through the lens of state response to crime, with the notable exception of homicide. Results reveal partial evidence for a declining behavioral trend in the case of homicide -- a finding that furthers current debates about the crime drop thesis. Rather mixed evidence is documented for robbery, theft and assault, but a common marked increase in the number of offences, suspects and convicts received into prison. Implications are discussed by reference to the emergent punitive turn in the Turkish penal regime, and enhanced police capacity to control crime.},
  langid = {english},
  keywords = {Crime statistics,Homicide,Police,Punitive turn,Turkey},
  file = {/home/work/Zotero/storage/4EPCL6ZU/S1756061619301910.html}
}

@misc{betancourtWhatProbabilisticStory2021,
  title = {({{What}}'s the {{Probabilistic Story}}) {{Modeling Glory}}?},
  author = {Betancourt, Michael},
  year = {2021},
  month = jul,
  urldate = {2024-06-25},
  howpublished = {https://betanalpha.github.io/assets/case\_studies/generative\_modeling.html},
  file = {/home/work/Zotero/storage/XBXGUBFQ/generative_modeling.html}
}

@article{blackwellUnifiedApproachMeasurement2017,
  title = {A {{Unified Approach}} to {{Measurement Error}} and {{Missing Data}}: {{Overview}} and {{Applications}}},
  shorttitle = {A {{Unified Approach}} to {{Measurement Error}} and {{Missing Data}}},
  author = {Blackwell, Matthew and Honaker, James and King, Gary},
  year = {2017},
  month = aug,
  journal = {Sociological Methods \& Research},
  volume = {46},
  number = {3},
  pages = {303--341},
  publisher = {SAGE Publications Inc},
  issn = {0049-1241},
  doi = {10.1177/0049124115585360},
  urldate = {2024-07-08},
  abstract = {Although social scientists devote considerable effort to mitigating measurement error during data collection, they often ignore the issue during data analysis. And although many statistical methods have been proposed for reducing measurement error-induced biases, few have been widely used because of implausible assumptions, high levels of model dependence, difficult computation, or inapplicability with multiple mismeasured variables. We develop an easy-to-use alternative without these problems; it generalizes the popular multiple imputation (MI) framework by treating missing data problems as a limiting special case of extreme measurement error and corrects for both. Like MI, the proposed framework is a simple two-step procedure, so that in the second step researchers can use whatever statistical method they would have if there had been no problem in the first place. We also offer empirical illustrations, open source software that implements all the methods described herein, and a companion article with technical details and extensions.},
  langid = {english},
  file = {/home/work/Zotero/storage/CNSMF6EJ/Blackwell et al. - 2017 - A Unified Approach to Measurement Error and Missin.pdf}
}

@article{buil-gilComparingMeasurementsViolent2022,
  title = {Comparing Measurements of Violent Crime in Local Communities: A Case Study in {{Islington}}, {{London}}},
  shorttitle = {Comparing Measurements of Violent Crime in Local Communities},
  author = {{Buil-Gil}, David and {Brunton-Smith}, Ian and {Pina-S{\'a}nchez}, Jose and Cernat, Alexandru},
  year = {2022},
  month = jul,
  journal = {Police Practice and Research},
  volume = {23},
  number = {4},
  pages = {489--506},
  publisher = {Routledge},
  issn = {1561-4263},
  doi = {10.1080/15614263.2022.2047047},
  urldate = {2023-02-22},
  abstract = {Police-recorded crime data are prone to measurement error, affecting our understanding of the nature of crime. Research has responded to this problem using data from surveys and emergency services. These data sources are not error-free, and data from different sources are not always easily comparable. This study compares violent crime data recorded by police, ambulance services, two surveys and computer simulations in Islington, London. Different data sources show remarkably different results. However, crime estimates become more similar, but still show different distributions, when crime rates are calculated using workday population as the denominator and log-transformed. Normalising crime rates by workday population controls for the fact that some data sources reflect offences' location while others refer to victims' residence, and log-transforming rates mitigates the biasing effect associated with some multiplicative forms of measurement error. Comparing multiple data sources allows for more accurate descriptions of the prevalence and distribution of crime.},
  keywords = {crime mapping,crime surveys,measurement error,official statistics,Police data}
}

@article{bushwayMagicStillThere2007a,
  title = {Is the {{Magic Still There}}? {{The Use}} of the {{Heckman Two-Step Correction}} for {{Selection Bias}} in {{Criminology}}},
  shorttitle = {Is the {{Magic Still There}}?},
  author = {Bushway, Shawn and Johnson, Brian D. and Slocum, Lee Ann},
  year = {2007},
  month = jun,
  journal = {Journal of Quantitative Criminology},
  volume = {23},
  number = {2},
  pages = {151--178},
  issn = {1573-7799},
  doi = {10.1007/s10940-007-9024-4},
  urldate = {2024-07-15},
  abstract = {Issues of selection bias pervade criminological research. Despite their ubiquity, considerable confusion surrounds various approaches for addressing sample selection. The most common approach for dealing with selection bias in criminology remains Heckman's [(1976) Ann Econ Social Measure 5:475--492] two-step correction. This technique has often been misapplied in criminological research. This paper highlights some common problems with its application, including its use with dichotomous dependent variables, difficulties with calculating the hazard rate, misestimated standard error estimates, and collinearity between the correction term and other regressors in the substantive model of interest. We also discuss the fundamental importance of exclusion restrictions, or theoretically determined variables that affect selection but not the substantive problem of interest. Standard statistical software can readily address some of these common errors, but the real problem with selection bias is substantive, not technical. Any correction for selection bias requires that the researcher understand the source and magnitude of the bias. To illustrate this, we apply a diagnostic technique by Stolzenberg and Relles [(1997) Am Sociol Rev 62:494--507] to help develop intuition about selection bias in the context of criminal sentencing research. Our investigation suggests that while Heckman's two-step correction can be an appropriate technique for addressing this bias, it is not a magic solution to the problem. Thoughtful consideration is therefore needed before employing this common but overused technique.},
  langid = {english},
  keywords = {Heckman correction,Sample selection,Selection bias,Two-step estimator},
  file = {/home/work/Zotero/storage/Y7IPPPQA/Bushway et al. - 2007 - Is the Magic Still There The Use of the Heckman T.pdf}
}

@article{carr-hillFindingThenCounting2012,
  title = {Finding and Then Counting Out-of-School Children},
  author = {{Carr-Hill}, Roy},
  year = {2012},
  month = mar,
  journal = {Compare: A Journal of Comparative and International Education},
  publisher = {Routledge},
  issn = {0305-7925},
  urldate = {2024-07-22},
  abstract = {In developing countries, population estimates and assessments of progress towards the Millennium Development Goals are based increasingly on household surveys. It is not recognised that they are i...},
  copyright = {Copyright British Association for International and Comparative Education},
  langid = {english},
  file = {/home/work/Zotero/storage/SGVX7V6A/03057925.2012.html}
}

@article{carr-hillMissingMillionsMeasuring2013,
  title = {Missing {{Millions}} and {{Measuring Development Progress}}},
  author = {{Carr-Hill}, Roy},
  year = {2013},
  month = jun,
  journal = {World Development},
  volume = {46},
  pages = {30--44},
  issn = {0305-750X},
  doi = {10.1016/j.worlddev.2012.12.017},
  urldate = {2023-03-02},
  abstract = {In developing countries, assessments of progress toward development goals are based increasingly on household surveys. These are inappropriate for obtaining information about the poorest. Typically, they omit by design: the homeless; those in institutions; and mobile, nomadic, or pastoralist populations. Moreover, in practice, household surveys typically under-represent: those in fragile, disjointed households; slum populations and areas posing security risks. Those six sub-groups constitute a large fraction of the ``poorest of the poor''. We estimate that 250 million are missed worldwide from the sampling frames of such surveys and from many censuses and their omission may well lead to substantial biases.},
  langid = {english},
  keywords = {accurate population counts,household surveys,inequalities,invisible populations,measurement of poverty,millenium development goals},
  file = {/home/work/Zotero/storage/6KUVSQ3M/S0305750X13000053.html}
}

@article{chattonCausalCookbookRecipes2024,
  title = {The {{Causal Cookbook}}: {{Recipes}} for {{Propensity Scores}}, {{G-Computation}}, and {{Doubly Robust Standardization}}},
  shorttitle = {The {{Causal Cookbook}}},
  author = {Chatton, Arthur and Rohrer, Julia M.},
  year = {2024},
  month = jan,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {7},
  number = {1},
  pages = {25152459241236149},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/25152459241236149},
  urldate = {2024-07-18},
  abstract = {Recent developments in the causal-inference literature have renewed psychologists' interest in how to improve causal conclusions based on observational data. A lot of the recent writing has focused on concerns of causal identification (under which conditions is it, in principle, possible to recover causal effects?); in this primer, we turn to causal estimation (how do researchers actually turn the data into an effect estimate?) and modern approaches to it that are commonly used in epidemiology. First, we explain how causal estimands can be defined rigorously with the help of the potential-outcomes framework, and we highlight four crucial assumptions necessary for causal inference to succeed (exchangeability, positivity, consistency, and noninterference). Next, we present three types of approaches to causal estimation and compare their strengths and weaknesses: propensity-score methods (in which the independent variable is modeled as a function of controls), g-computation methods (in which the dependent variable is modeled as a function of both controls and the independent variable), and doubly robust estimators (which combine models for both independent and dependent variables). A companion R Notebook is available at github.com/ArthurChatton/CausalCookbook. We hope that this nontechnical introduction not only helps psychologists and other social scientists expand their causal toolbox but also facilitates communication across disciplinary boundaries when it comes to causal inference, a research goal common to all fields of research.},
  langid = {english},
  file = {/home/work/Zotero/storage/DE4LMBZX/Chatton and Rohrer - 2024 - The Causal Cookbook Recipes for Propensity Scores.pdf}
}

@article{chinQuestionableResearchPractices2023,
  title = {Questionable {{Research Practices}} and {{Open Science}} in {{Quantitative Criminology}}},
  author = {Chin, Jason M. and Pickett, Justin T. and Vazire, Simine and Holcombe, Alex O.},
  year = {2023},
  month = mar,
  journal = {Journal of Quantitative Criminology},
  volume = {39},
  number = {1},
  pages = {21--51},
  issn = {1573-7799},
  doi = {10.1007/s10940-021-09525-6},
  urldate = {2024-07-23},
  abstract = {Questionable research practices (QRPs) lead to incorrect research results and contribute to irreproducibility in science. Researchers and institutions have proposed open science practices (OSPs) to improve the detectability of QRPs and the credibility of science. We examine the prevalence of QRPs and OSPs in criminology, and researchers' opinions of those practices.},
  langid = {english},
  keywords = {Meta-research,Open science,Questionable research practices,Reproducibility},
  file = {/home/work/Zotero/storage/RZYQ59TC/Chin et al. - 2023 - Questionable Research Practices and Open Science i.pdf}
}

@article{d.redelingsWhyConfidenceIntervals2012,
  title = {Why {{Confidence Intervals Should}} Be {{Used}} in {{Reporting Studies}} of {{Complete Populations}}},
  author = {D. Redelings, Matthew and Sorvillo, Frank and V. Smith, Lisa and Greenland, Sander},
  year = {2012},
  month = oct,
  volume = {5},
  number = {1},
  doi = {10.2174/1874944501205010052},
  urldate = {2024-07-22},
  abstract = {Why Confidence Intervals Should be Used in Reporting Studies of Complete Populations},
  langid = {english},
  file = {/home/work/Zotero/storage/YXDDIG55/D. Redelings et al. - 2012 - Why Confidence Intervals Should be Used in Reporti.pdf}
}

@article{degtiarReviewGeneralizabilityTransportability2023a,
  title = {A {{Review}} of {{Generalizability}} and {{Transportability}}},
  author = {Degtiar, Irina and Rose, Sherri},
  year = {2023},
  month = mar,
  journal = {Annual Review of Statistics and Its Application},
  volume = {10},
  number = {Volume 10, 2023},
  pages = {501--524},
  publisher = {Annual Reviews},
  issn = {2326-8298, 2326-831X},
  doi = {10.1146/annurev-statistics-042522-103837},
  urldate = {2024-06-14},
  abstract = {When assessing causal effects, determining the target population to which the results are intended to generalize is a critical decision. Randomized and observational studies each have strengths and limitations for estimating causal effects in a target population. Estimates from randomized data may have internal validity but are often not representative of the target population. Observational data may better reflect the target population, and hence be more likely to have external validity, but are subject to potential bias due to unmeasured confounding. While much of the causal inference literature has focused on addressing internal validity bias, both internal and external validity are necessary for unbiased estimates in a target population. This article presents a framework for addressing external validity bias, including a synthesis of approaches for generalizability and transportability, and the assumptions they require, as well as tests for the heterogeneity of treatment effects and differences between study and target populations.},
  langid = {english},
  file = {/home/work/Zotero/storage/PH98BART/Degtiar and Rose - 2023 - A Review of Generalizability and Transportability.pdf;/home/work/Zotero/storage/YWNSIYNJ/annurev-statistics-042522-103837.html}
}

@book{dignazioDataFeminism2020,
  title = {Data {{Feminism}}},
  author = {D'Ignazio, Catherine and Klein, Lauren F.},
  editor = {Weinberger, David},
  year = {2020},
  month = mar,
  series = {Strong {{Ideas}}},
  publisher = {MIT Press},
  address = {Cambridge, MA, USA},
  abstract = {A new way of thinking about data science and data ethics that is informed by the ideas of intersectional feminism.},
  isbn = {978-0-262-04400-4},
  langid = {english},
  file = {/home/work/Zotero/storage/9JWEA28A/data-feminism.mitpress.mit.edu.html}
}

@article{doidgeReflectionsModernMethods2019a,
  title = {Reflections on Modern Methods: Linkage Error Bias},
  shorttitle = {Reflections on Modern Methods},
  author = {Doidge, James C and Harron, Katie L},
  year = {2019},
  month = dec,
  journal = {International Journal of Epidemiology},
  volume = {48},
  number = {6},
  pages = {2050--2060},
  issn = {0300-5771},
  doi = {10.1093/ije/dyz203},
  urldate = {2024-07-09},
  abstract = {Linked data are increasingly being used for epidemiological research, to enhance primary research, and in planning, monitoring and evaluating public policy and services. Linkage error (missed links between records that relate to the same person or false links between unrelated records) can manifest in many ways: as missing data, measurement error and misclassification, unrepresentative sampling, or as a special combination of these that is specific to analysis of linked data: the merging and splitting of people that can occur when two hospital admission records are counted as one person admitted twice if linked and two people admitted once if not. Through these mechanisms, linkage error can ultimately lead to information bias and selection bias; so identifying relevant mechanisms is key in quantitative bias analysis. In this article we introduce five key concepts and a study classification system for identifying which mechanisms are relevant to any given analysis. We provide examples and discuss options for estimating parameters for bias analysis. This conceptual framework provides the `links' between linkage error, information bias and selection bias, and lays the groundwork for quantitative bias analysis for linkage error.},
  file = {/home/work/Zotero/storage/JTPCA3ER/Doidge and Harron - 2019 - Reflections on modern methods linkage error bias.pdf;/home/work/Zotero/storage/BUGKD83Q/5601471.html}
}

@article{fohringPuttingFaceDark2014,
  title = {Putting a Face on the Dark Figure: {{Describing}} Victims Who Don't Report Crime},
  shorttitle = {Putting a Face on the Dark Figure},
  author = {Fohring, Stephanie},
  year = {2014},
  journal = {Temida},
  volume = {17},
  number = {4},
  pages = {3--18},
  urldate = {2024-06-25},
  abstract = {Since the inception of large scale victimisation surveys a considerable amount of research has been conducted investigating the so called `dark figure' of unreported crime. Although this figure has consistently hovered around 60\% of all victims, recent research reveals little about those who choose not to pursue formal avenues of justice. This article thus seeks to open a dialogue which focuses on the actual people behind the dark figure. It uses examples from the Scottish Crime and Justice Survey to describe these individuals and to explore explanations for their non-reporting. It highlights the importance of deprivation and vulnerability with regards to reporting crime but also the initial risk of victimisation. It concludes by arguing that the lack of focus on victims who don't report leaves them vulnerable and invisible to the eyes of policy makers and the criminal justice system.}
}

@article{gaeblerCausalFrameworkObservational2022,
  title = {A {{Causal Framework}} for {{Observational Studies}} of {{Discrimination}}},
  author = {Gaebler, Johann and Cai, William and Basse, Guillaume and Shroff, Ravi and Goel, Sharad and Hill, Jennifer},
  year = {2022},
  month = dec,
  journal = {Statistics and Public Policy},
  volume = {9},
  number = {1},
  pages = {26--48},
  publisher = {Taylor \& Francis},
  issn = {null},
  doi = {10.1080/2330443X.2021.2024778},
  urldate = {2022-07-19},
  abstract = {In studies of discrimination, researchers often seek to estimate a causal effect of race or gender on outcomes. For example, in the criminal justice context, one might ask whether arrested individuals would have been subsequently charged or convicted had they been a different race. It has long been known that such counterfactual questions face measurement challenges related to omitted-variable bias, and conceptual challenges related to the definition of causal estimands for largely immutable characteristics. Another concern, which has been the subject of recent debates, is post-treatment bias: many studies of discrimination condition on apparently intermediate outcomes, like being arrested, that themselves may be the product of discrimination, potentially corrupting statistical estimates. There is, however, reason to be optimistic. By carefully defining the estimand---and by considering the precise timing of events---we show that a primary causal quantity of interest in discrimination studies can be estimated under an ignorability condition that may hold approximately in some observational settings. We illustrate these ideas by analyzing both simulated data and the charging decisions of a prosecutor's office in a large county in the United States.},
  keywords = {Applications and case studies,Linear,Simulation},
  file = {/home/work/Zotero/storage/QCW685TI/Gaebler et al. - 2022 - A Causal Framework for Observational Studies of Di.pdf;/home/work/Zotero/storage/RTHDZD26/2330443X.2021.html}
}

@article{gayleStarkRealitiesReproducible2022,
  title = {The {{Stark}} Realities of Reproducible Statistically Orientated Sociological Research: {{Some}} Newer Rules of the Sociological Method},
  shorttitle = {The {{Stark}} Realities of Reproducible Statistically Orientated Sociological Research},
  author = {Gayle, Vernon and Connelly, Roxanne},
  year = {2022},
  month = nov,
  journal = {Methodological Innovations},
  volume = {15},
  number = {3},
  pages = {207--221},
  publisher = {SAGE Publications Ltd},
  issn = {2059-7991},
  doi = {10.1177/20597991221111681},
  urldate = {2024-07-18},
  abstract = {There is increasing concern that research is not transparent and that empirical results are often impossible to reproduce. Guidelines for undertaking reproducible research have been proposed in a number of academic areas (e.g. computational economics, psychology and medical research), however currently there are no guidelines for sociological research. This methodological paper provides guidance for undertaking reproducible statistically orientated sociological research. We provide an extended demonstration of the issues associated with reproducing results and undertaking transparent analyses. We draw on suitable concepts and techniques from open research, e-research and computing. We propose a set of Newer Rules of the Sociological Method, for undertaking transparent statistically orientated sociological research that supports reproducibility.},
  langid = {english},
  file = {/home/work/Zotero/storage/CABDKYWR/Gayle and Connelly - 2022 - The Stark realities of reproducible statistically .pdf}
}

@article{gelmanAveragePredictiveComparisons2007,
  title = {Average {{Predictive Comparisons}} for {{Models}} with {{Nonlinearity}}, {{Interactions}}, and {{Variance Components}}},
  author = {Gelman, Andrew and Pardoe, Iain},
  year = {2007},
  month = aug,
  journal = {Sociological Methodology},
  volume = {37},
  number = {1},
  pages = {23--51},
  issn = {0081-1750, 1467-9531},
  doi = {10.1111/j.1467-9531.2007.00181.x},
  urldate = {2019-09-11},
  langid = {english},
  file = {/home/work/Zotero/storage/WGEVEL3C/j.1467-9531.2007.00181.html}
}

@article{gelmanWhatStandardError2023,
  title = {What Is a Standard Error?},
  author = {Gelman, Andrew},
  year = {2023},
  month = nov,
  journal = {Journal of Econometrics},
  volume = {237},
  number = {1},
  pages = {105516},
  issn = {0304-4076},
  doi = {10.1016/j.jeconom.2023.105516},
  urldate = {2024-07-22},
  file = {/home/work/Zotero/storage/8TP8MNIF/S0304407623002324.html}
}

@incollection{greenlandSensitivityAnalysisBias2014,
  title = {Sensitivity {{Analysis}} and {{Bias Analysis}}},
  booktitle = {Handbook of {{Epidemiology}}},
  author = {Greenland, Sander},
  editor = {Ahrens, Wolfgang and Pigeot, Iris},
  year = {2014},
  pages = {685--706},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-0-387-09834-0_60},
  urldate = {2024-06-14},
  abstract = {Over recent decades recognition has grown that the conventional statistical models used to analyze epidemiological data cannot be reasonably claimed to be correct in the way most textbooks treat them to be. In particular, conventional models for epidemiological data-generating processes cannot be credibly taken to represent targets of primary scientific interest. For example, a logistic model for the regression of an observed disease indicator on covariate measurements would only rarely correspond closely to the causal effects on disease of the risk factors represented by the measurements. The discrepancies between the statistical model parameters and the underlying target effects are often called systematic errors, biases, or bias sources. Large biases undermine the interpretation of both frequentist statistics (such as confidence intervals) and Bayesian statistics (such as posterior intervals).},
  isbn = {978-0-387-09834-0},
  langid = {english},
  keywords = {Bias Analysis,Bias Parameter,False Recall,Prior Distribution,Target Parameter},
  file = {/home/work/Zotero/storage/BYZZLSMQ/Greenland - 2014 - Sensitivity Analysis and Bias Analysis.pdf}
}

@book{hilbeModelingCountData2014,
  title = {Modeling {{Count Data}}},
  author = {Hilbe, Joseph M.},
  year = {2014},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9781139236065},
  urldate = {2024-07-22},
  abstract = {This entry-level text offers clear and concise guidelines on how to select, construct, interpret, and evaluate count data. Written for researchers with little or no background in advanced statistics, the book presents treatments of all major models using numerous tables, insets, and detailed modeling suggestions. It begins by demonstrating the fundamentals of modeling count data, including a thorough presentation of the Poisson model. It then works up to an analysis of the problem of overdispersion and of the negative binomial model, and finally to the many variations that can be made to the base count models. Examples in Stata, R, and SAS code enable readers to adapt models for their own purposes, making the text an ideal resource for researchers working in health, ecology, econometrics, transportation, and other fields.},
  isbn = {978-1-107-02833-3},
  file = {/home/work/Zotero/storage/9FA4BBGG/BFEB3985905CA70523D9F98DA8E64D08.html}
}

@book{hilbeNegativeBinomialRegression2011,
  title = {Negative {{Binomial Regression}}},
  author = {Hilbe, Joseph M.},
  year = {2011},
  edition = {2},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511973420},
  urldate = {2024-07-22},
  abstract = {This second edition of Hilbe's Negative Binomial Regression is a substantial enhancement to the popular first edition. The only text devoted entirely to the negative binomial model and its many variations, nearly every model discussed in the literature is addressed. The theoretical and distributional background of each model is discussed, together with examples of their construction, application, interpretation and evaluation. Complete Stata and R codes are provided throughout the text, with additional code (plus SAS), derivations and data provided on the book's website. Written for the practising researcher, the text begins with an examination of risk and rate ratios, and of the estimating algorithms used to model count data. The book then gives an in-depth analysis of Poisson regression and an evaluation of the meaning and nature of overdispersion, followed by a comprehensive analysis of the negative binomial distribution and of its parameterizations into various models for evaluating count data.},
  isbn = {978-0-521-19815-8},
  file = {/home/work/Zotero/storage/PLDEPGN7/12D6281A46B9A980DC6021080C9419E7.html}
}

@misc{hopeEffectThirdParty2023,
  title = {The {{Effect}} of `{{Third Party}}' {{Pressure}} on {{Police Crime Recording Practice}}},
  author = {Hope, Tim},
  year = {2023},
  month = dec,
  journal = {CrimRxiv},
  urldate = {2024-06-25},
  abstract = {This technical note was submitted as evidence to an inquiry into police practice in recording crime held by the Public Administration Select Committee of the House of Commons, UK Parliament. This note concerns the effect of `third-parties' (sources other than the complainant who reports an incident and the police officers who deal with that report) on the recording of crime incidents. Third-party pressures have a systematic influence on the aggregate patterns and trends observed in the recorded crime statistics. The gap between the public's propensity to report crime to the police and the police decision to record it creates a `grey figure'. The grey figure also reflects systematic performance adjustment on the part of the police who seek to reconcile third party pressures with {$<>$} the capacities and resources at their disposal. Three strategies of adjustment can be identified: `not-crimeing', `no-crimeing', and `down-crimeing'. Evidence is presented whereby these possible effects can be inferred.},
  langid = {english},
  file = {/home/work/Zotero/storage/TQ875A87/Hope - 2023 - The Effect of ‘Third Party’ Pressure on Police Cri.pdf}
}

@article{hunterEquityJusticeCrime2016,
  title = {Equity, Justice and the Crime Drop: The Case of Burglary in {{England}} and {{Wales}}},
  shorttitle = {Equity, Justice and the Crime Drop},
  author = {Hunter, James and Tseloni, Andromachi},
  year = {2016},
  month = apr,
  journal = {Crime Science},
  volume = {5},
  number = {1},
  pages = {3},
  issn = {2193-7680},
  doi = {10.1186/s40163-016-0051-z},
  urldate = {2020-08-21},
  abstract = {Burglary in England and Wales fell by 67~\% between 1993 and 2008/09. This study examines whether this fall was equitable across different population segments (with respect to their socio-economic characteristics) and area types. In particular, it estimates the extent of burglary falls and any changes in the victimisation divide across socio-economic (population) groups taking into account group composition. To this end, it compares their burglary incidence rates based on burglary count models of the 1994 and 2008/09 Crime Survey for England and Wales data. The results show that some socio-economic groups experienced inequitable burglary falls, and relative to others continue to experience burglaries at higher rates after the crime drop than before.},
  langid = {english}
}

@article{ImprovingVictimisationEstimatesa,
  title = {Improving {{Victimisation Estimates Derived}} from the {{Crime Survey}} for {{England}} and {{Wales}}},
  langid = {english},
  file = {/home/work/Zotero/storage/TLMDUR8M/Improving Victimisation Estimates Derived from the.pdf}
}

@article{kawabataQuantitativeBiasAnalysis2023,
  title = {Quantitative Bias Analysis in Practice: Review of Software for Regression with Unmeasured Confounding},
  shorttitle = {Quantitative Bias Analysis in Practice},
  author = {Kawabata, Emily and Tilling, Kate and Groenwold, Rolf H. H. and Hughes, Rachael A.},
  year = {2023},
  month = may,
  journal = {BMC Medical Research Methodology},
  volume = {23},
  pages = {111},
  issn = {1471-2288},
  doi = {10.1186/s12874-023-01906-8},
  urldate = {2024-07-08},
  abstract = {Background Failure to appropriately account for unmeasured confounding may lead to erroneous conclusions. Quantitative bias analysis (QBA) can be used to quantify the potential impact of unmeasured confounding or how much unmeasured confounding would be needed to change a study's conclusions. Currently, QBA methods are not routinely implemented, partly due to a lack of knowledge about accessible software. Also, comparisons of QBA methods have focused on analyses with a binary outcome. Methods We conducted a systematic review of the latest developments in QBA software published between 2011 and 2021. Our inclusion criteria were software that did not require adaption (i.e., code changes) before application, was still available in 2022, and accompanied by documentation. Key properties of each software tool were identified. We provide a detailed description of programs applicable for a linear regression analysis, illustrate their application using two data examples and provide code to assist researchers in future use of these programs. Results Our review identified 21 programs with {\textbackslash}documentclass[12pt]\{minimal\} 				{\textbackslash}usepackage\{amsmath\} 				{\textbackslash}usepackage\{wasysym\}  				{\textbackslash}usepackage\{amsfonts\}  				{\textbackslash}usepackage\{amssymb\}  				{\textbackslash}usepackage\{amsbsy\} 				{\textbackslash}usepackage\{mathrsfs\} 				{\textbackslash}usepackage\{upgreek\} 				{\textbackslash}setlength\{{\textbackslash}oddsidemargin\}\{-69pt\} 				{\textbackslash}begin\{document\}\$\$62{\textbackslash}\%\$\${\textbackslash}end\{document\}62\% created post 2016. All are implementations of a deterministic QBA with {\textbackslash}documentclass[12pt]\{minimal\} 				{\textbackslash}usepackage\{amsmath\} 				{\textbackslash}usepackage\{wasysym\}  				{\textbackslash}usepackage\{amsfonts\}  				{\textbackslash}usepackage\{amssymb\}  				{\textbackslash}usepackage\{amsbsy\} 				{\textbackslash}usepackage\{mathrsfs\} 				{\textbackslash}usepackage\{upgreek\} 				{\textbackslash}setlength\{{\textbackslash}oddsidemargin\}\{-69pt\} 				{\textbackslash}begin\{document\}\$\$81{\textbackslash}\%\$\${\textbackslash}end\{document\}81\% available in the free software R. There are programs applicable when the analysis of interest is a regression of binary, continuous or survival outcomes, and for matched and mediation analyses. We identified five programs implementing differing QBAs for a continuous outcome: treatSens, causalsens, sensemakr, EValue, and konfound. When applied to~one of our illustrative examples, causalsens incorrectly indicated sensitivity to unmeasured confounding whereas the other four programs indicated robustness. sensemakr performs the most detailed QBA and includes a benchmarking feature for multiple unmeasured confounders. Conclusions Software is now available to implement a QBA for a range of different analyses. However, the diversity of methods, even for the same analysis of interest, presents challenges to their widespread uptake. Provision of detailed QBA guidelines would be highly beneficial. Supplementary Information The online version contains supplementary material available at 10.1186/s12874-023-01906-8.},
  pmcid = {PMC10158211},
  pmid = {37142961},
  file = {/home/work/Zotero/storage/V8YL7U6Q/Kawabata et al. - 2023 - Quantitative bias analysis in practice review of .pdf}
}

@article{kingMakingMostStatistical2000,
  title = {Making the {{Most}} of {{Statistical Analyses}}: {{Improving Interpretation}} and {{Presentation}}},
  shorttitle = {Making the {{Most}} of {{Statistical Analyses}}},
  author = {King, Gary and Tomz, Michael and Wittenberg, Jason},
  year = {2000},
  journal = {American Journal of Political Science},
  volume = {44},
  pages = {341--355},
  file = {/home/work/Zotero/storage/YG79I8Z3/making-abs.html}
}

@article{kitsuseNoteUsesOfficial1963,
  title = {A {{Note}} on the {{Uses}} of {{Official Statistics}}},
  author = {Kitsuse, John I. and Cicourel, Aaron V.},
  year = {1963},
  journal = {Social Problems},
  volume = {11},
  number = {2},
  eprint = {799220},
  eprinttype = {jstor},
  pages = {131--139},
  publisher = {[Oxford University Press, Society for the Study of Social Problems]},
  issn = {0037-7791},
  doi = {10.2307/799220},
  urldate = {2022-07-18}
}

@article{knoxAdministrativeRecordsMask2020a,
  title = {Administrative {{Records Mask Racially Biased Policing}}},
  author = {Knox, Dean and Lowe, Will and Mummolo, Jonathan},
  year = {2020},
  month = aug,
  journal = {American Political Science Review},
  volume = {114},
  number = {3},
  pages = {619--637},
  publisher = {Cambridge University Press},
  issn = {0003-0554, 1537-5943},
  doi = {10.1017/S0003055420000039},
  urldate = {2024-01-24},
  abstract = {Researchers often lack the necessary data to credibly estimate racial discrimination in policing. In particular, police administrative records lack information on civilians police observe but do not investigate. In this article, we show that if police racially discriminate when choosing whom to investigate, analyses using administrative records to estimate racial discrimination in police behavior are statistically biased, and many quantities of interest are unidentified---even among investigated individuals---absent strong and untestable assumptions. Using principal stratification in a causal mediation framework, we derive the exact form of the statistical bias that results from traditional estimation. We develop a bias-correction procedure and nonparametric sharp bounds for race effects, replicate published findings, and show the traditional estimator can severely underestimate levels of racially biased policing or mask discrimination entirely. We conclude by outlining a general and feasible design for future studies that is robust to this inferential snare.},
  langid = {english},
  file = {/home/work/Zotero/storage/GHTI6538/Knox et al. - 2020 - Administrative Records Mask Racially Biased Polici.pdf}
}

@article{lundbergWhatYourEstimand2021a,
  title = {What {{Is Your Estimand}}? {{Defining}} the {{Target Quantity Connects Statistical Evidence}} to {{Theory}}},
  shorttitle = {What {{Is Your Estimand}}?},
  author = {Lundberg, Ian and Johnson, Rebecca and Stewart, Brandon M.},
  year = {2021},
  month = jun,
  journal = {American Sociological Review},
  volume = {86},
  number = {3},
  pages = {532--565},
  publisher = {SAGE Publications Inc},
  issn = {0003-1224},
  doi = {10.1177/00031224211004187},
  urldate = {2024-07-18},
  abstract = {We make only one point in this article. Every quantitative study must be able to answer the question: what is your estimand? The estimand is the target quantity---the purpose of the statistical analysis. Much attention is already placed on how to do estimation; a similar degree of care should be given to defining the thing we are estimating. We advocate that authors state the central quantity of each analysis---the theoretical estimand---in precise terms that exist outside of any statistical model. In our framework, researchers do three things: (1) set a theoretical estimand, clearly connecting this quantity to theory; (2) link to an empirical estimand, which is informative about the theoretical estimand under some identification assumptions; and (3) learn from data. Adding precise estimands to research practice expands the space of theoretical questions, clarifies how evidence can speak to those questions, and unlocks new tools for estimation. By grounding all three steps in a precise statement of the target quantity, our framework connects statistical evidence to theory.},
  langid = {english},
  file = {/home/work/Zotero/storage/VJDDXTXZ/Lundberg et al. - 2021 - What Is Your Estimand Defining the Target Quantit.pdf}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
  title = {Statistical {{Rethinking}}: {{A Bayesian Course}} with {{Examples}} in {{R}} and {{STAN}}},
  shorttitle = {Statistical {{Rethinking}}},
  author = {McElreath, Richard},
  year = {2020},
  month = mar,
  publisher = {CRC Press},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds your knowledge of and confidence in making inferences from data. Reflecting the need for scripting in today's model-based statistics, the book pushes you to perform step-by-step calculations that are usually automated. This unique computational approach ensures that you understand enough of the details to make reasonable choices and interpretations in your own modeling work.  The text presents causal inference and generalized linear multilevel models from a simple Bayesian perspective that builds on information theory and maximum entropy. The core material ranges from the basics of regression to advanced multilevel models. It also presents measurement error, missing data, and Gaussian process models for spatial and phylogenetic confounding.  The second edition emphasizes the directed acyclic graph (DAG) approach to causal inference, integrating DAGs into many examples. The new edition also contains new material on the design of prior distributions, splines, ordered categorical predictors, social relations models, cross-validation, importance sampling, instrumental variables, and Hamiltonian Monte Carlo. It ends with an entirely new chapter that goes beyond generalized linear modeling, showing how domain-specific scientific models can be built into statistical analyses.  Features   Integrates working code into the main text   Illustrates concepts through worked data analysis examples   Emphasizes understanding assumptions and how assumptions are reflected in code   Offers more detailed explanations of the mathematics in optional sections   Presents examples of using the dagitty R package to analyze causal graphs   Provides the rethinking R package on the author's website and on GitHub},
  googlebooks = {6H\_WDwAAQBAJ},
  isbn = {978-0-429-63914-2},
  langid = {english},
  keywords = {Mathematics / Probability & Statistics / General},
  file = {/home/work/Zotero/storage/8846FUMX/9780367139919.html}
}

@article{nixWhenPolicePull2024,
  title = {When Police Pull Back: {{Neighborhood-level}} Effects of de-Policing on Violent and Property Crime, a Research Note},
  shorttitle = {When Police Pull Back},
  author = {Nix, Justin and Huff, Jessica and Wolfe, Scott E. and Pyrooz, David C. and Mourtgos, Scott M.},
  year = {2024},
  journal = {Criminology},
  volume = {62},
  number = {1},
  pages = {156--171},
  issn = {1745-9125},
  doi = {10.1111/1745-9125.12363},
  urldate = {2024-07-18},
  abstract = {Many U.S. cities witnessed both de-policing and increased crime in 2020, yet whether the former contributed to the latter remains unclear. Indeed, much of what is known about the effects of proactive policing on crime comes from studies that evaluated highly focused interventions atypical of day-to-day policing, used cities as the unit of analysis, or could not rule out endogeneity. This study addresses each of these issues, thereby advancing the evidence base concerning the effects of policing on crime. Leveraging two exogenous shocks presented by the onset of the coronavirus 2019 (COVID-19) pandemic and social unrest after the murder of George Floyd, we evaluated the effects of sudden and sustained reductions in high-discretion policing on crime at the neighborhood level in Denver, Colorado. Multilevel models accounting for trends in prior police activity, neighborhood structure, seasonality, and population mobility revealed mixed results. On the one hand, large-scale reductions in stops and drug-related arrests were associated with significant increases in violent and property crimes, respectively. On the other hand, fewer disorder arrests did not affect crime. These results were not universal across neighborhoods. We discuss the implications of these findings in light of debates concerning the appropriate role of policing in the 21st century.},
  copyright = {{\copyright} 2024 The Authors. Criminology published by Wiley Periodicals LLC on behalf of American Society of Criminology.},
  langid = {english},
  keywords = {COVID-19,crime,George Floyd,neighborhoods,policing,violence},
  file = {/home/work/Zotero/storage/IZZ6WGYH/Nix et al. - 2024 - When police pull back Neighborhood-level effects .pdf;/home/work/Zotero/storage/RQ3643LE/1745-9125.html}
}

@misc{pina-sanchezEthnicDisparitiesSentencing2022,
  title = {Ethnic {{Disparities}} in {{Sentencing}}: {{Warranted}} or {{Unwarranted}}?},
  shorttitle = {Ethnic {{Disparities}} in {{Sentencing}}},
  author = {{Pina-S{\'a}nchez}, Jose and Geneletti, Sara and Veiga, Ana and Morales, Ana and Guilfoyle, Eoin},
  year = {2022},
  month = sep,
  publisher = {OSF},
  doi = {10.31235/osf.io/k8bsg},
  urldate = {2024-06-25},
  abstract = {Large research efforts have been directed at the exploration of ethnic disparities in the criminal justice system, documenting harsher treatment of minority ethnic defendants, across offence types, criminal justice decisions, and jurisdictions. However, most studies on the topic have relied on observational data, which can only approximate `like with like' comparisons. As a result, researchers, practitioners and policy-makers have often been wary of interpreting such disparities as evidence of discrimination. We use causal diagrams to lay out explicitly the different ways estimates of ethnic discrimination derived from observational data could be biased. Beyond the commonly acknowledged problem of unobserved case characteristics, we also discuss other less well-known, yet likely more consequential problems: measurement error in the form of racially-determined case characteristics or as a result of high heterogeneity within the `Whites' reference group, and selection bias from non-response and missing offender's ethnicity data. We apply such causal framework to review findings from two recent studies showing ethnic disparities in custodial sentences imposed at the Crown Court (England and Wales), questioning whether the reported disparities should be interpreted as evidence of discrimination. We also use simulations to recreate the most comprehensive of those studies, and demonstrate how the reported ethnic disparities appear robust to a problem of unobserved case characteristics. We conclude that ethnic disparities observed in the Crown Court are likely reflecting evidence of direct discrimination in sentencing.},
  archiveprefix = {OSF},
  langid = {american},
  keywords = {Crown Court,DAGs,Discrimination,Disparities,Sensitivity Analysis,Sentencing},
  file = {/home/work/Zotero/storage/QI7MYX5J/Pina-Sánchez et al. - 2022 - Ethnic Disparities in Sentencing Warranted or Unw.pdf}
}

@article{pina-sanchezTacklingSelectionBias2020,
  title = {Tackling Selection Bias in Sentencing Data Analysis: A New Approach Based on a Scale of Severity},
  shorttitle = {Tackling Selection Bias in Sentencing Data Analysis},
  author = {{Pina-S{\'a}nchez}, Jose and Gosling, John Paul},
  year = {2020},
  month = jun,
  journal = {Quality \& Quantity},
  volume = {54},
  number = {3},
  pages = {1047--1073},
  issn = {1573-7845},
  doi = {10.1007/s11135-020-00973-z},
  urldate = {2024-07-15},
  abstract = {For reasons of methodological convenience statistical models analysing judicial decisions tend to focus on the duration of custodial sentences. These types of sentences are however quite rare (7\% of the total in England and Wales), which generates a serious problem of selection bias. Typical adjustments employed in the literature, such as Tobit models, are based on questionable assumptions and are incapable to discriminate between different types of non-custodial sentences (such as discharges, fines, community orders, or suspended sentences). Here we implement an original approach to model custodial and non-custodial sentence outcomes simultaneously avoiding problems of selection bias while making the most of the information recorded for each of them. This is achieved by employing Pina-S{\'a}nchez et al. (Br J Criminol 59:979--1001, 2019) scale of sentence severity as the outcome variable of a Bayesian regression model. A sample of 7242 theft offences sentenced in the Crown Court is used to further illustrate: (a) the pervasiveness of selection bias in studies restricted to custodial sentences, which leads us to question the external validity of previous studies in the literature limited to custodial sentence length; and (b) the inadequacy of Tobit models and similar methods used in the literature to adjust for such bias.},
  langid = {english},
  keywords = {Bayesian statistics,Paired comparison,Selection bias,Sentencing,Severity,Tobit models},
  file = {/home/work/Zotero/storage/PBHCK9W7/Pina-Sánchez and Gosling - 2020 - Tackling selection bias in sentencing data analysi.pdf}
}

@article{sampsonDoesMarriageReduce2006,
  title = {Does Marriage Reduce Crime? {{A}} Counterfactual Approach to within-Individual Causal Effects},
  shorttitle = {Does Marriage Reduce Crime?},
  author = {Sampson, Robert J. and Laub, John H. and Wimer, Christopher},
  year = {2006},
  journal = {Criminology: An Interdisciplinary Journal},
  volume = {44},
  number = {3},
  pages = {465--508},
  publisher = {Blackwell Publishing},
  address = {United Kingdom},
  issn = {1745-9125},
  doi = {10.1111/j.1745-9125.2006.00055.x},
  abstract = {Although marriage is associated with a plethora of adult outcomes, its causal status remains controversial in the absence of experimental evidence. We address this problem by introducing a counter factual life course approach that applies inverse probability of treatment weighting (IPTW) to yearly longitudinal data on marriage, crime, and shared covariates in a sample of 500 high-risk boys followed prospectively from adolescence to age 32. The data consist of criminal histories and death records for all 500 men plus personal interviews, using a life history calendar, with a stratified subsample of 52 men followed to age 70. These data are linked to an extensive battery of individual and family background measures gathered from childhood to age 17-before entry into marriage. Applying IPTW to multiple specifications that also incorporate extensive time-varying covariates in adulthood, being married is associated with an average reduction of approximately 35 percent in the odds of crime compared to non married states for the same man. These results are robust, supporting the inference that states of marriage causally inhibit crime over the life course. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Causality,Crime,Criminal Offenders,Marriage},
  file = {/home/work/Zotero/storage/WGS6EFDQ/2008-07491-001.html}
}

@article{sankaranGenerativeModelsInterdisciplinary2023,
  title = {Generative {{Models}}: {{An Interdisciplinary Perspective}}},
  shorttitle = {Generative {{Models}}},
  author = {Sankaran, Kris and Holmes, Susan P.},
  year = {2023},
  month = mar,
  journal = {Annual Review of Statistics and Its Application},
  volume = {10},
  number = {Volume 10, 2023},
  pages = {325--352},
  publisher = {Annual Reviews},
  issn = {2326-8298, 2326-831X},
  doi = {10.1146/annurev-statistics-033121-110134},
  urldate = {2024-06-25},
  abstract = {By linking conceptual theories with observed data, generative models can support reasoning in complex situations. They have come to play a central role both within and beyond statistics, providing the basis for power analysis in molecular biology, theory building in particle physics, and resource allocation in epidemiology, for example. We introduce the probabilistic and computational concepts underlying modern generative models and then analyze how they can be used to inform experimental design, iterative model refinement, goodness-of-fit evaluation, and agent based simulation. We emphasize a modular view of generative mechanisms and discuss how they can be flexibly recombined in new problem contexts. We provide practical illustrations throughout, and code for reproducing all examples is available at https://github.com/krisrs1128/generative\_review. Finally, we observe how research in generative models is currently split across several islands of activity, and we highlight opportunities lying at disciplinary intersections.},
  langid = {english},
  file = {/home/work/Zotero/storage/4A5C55A3/Sankaran and Holmes - 2023 - Generative Models An Interdisciplinary Perspectiv.pdf;/home/work/Zotero/storage/TP5GUCGB/annurev-statistics-033121-110134.html}
}

@misc{scottishwomensaidResponseConsultationScottish2021,
  title = {Response to the Consultation on the {{Scottish Crime}} and {{Justice Survey}} ({{SCJS}}), {{December}} 2021},
  author = {{Scottish Women's Aid}},
  year = {2021},
  month = dec,
  urldate = {2023-03-01},
  howpublished = {https://womensaid.scot/wp-content/uploads/2022/04/SWA-response-to-Scottish-Crime-and-Justice-Survey-consultation.pdf}
}

@article{simesPlacePunishmentSpatial2018a,
  title = {Place and {{Punishment}}: {{The Spatial Context}} of {{Mass Incarceration}}},
  shorttitle = {Place and {{Punishment}}},
  author = {Simes, Jessica T.},
  year = {2018},
  month = jun,
  journal = {Journal of Quantitative Criminology},
  volume = {34},
  number = {2},
  pages = {513--533},
  issn = {1573-7799},
  doi = {10.1007/s10940-017-9344-y},
  urldate = {2024-06-14},
  abstract = {Research on race and urban poverty views incarceration as a new and important aspect of social disadvantage in inner-city neighborhoods. However, in quantitative studies of the spatial distribution of imprisonment across neighborhoods, the pattern outside urban areas has not been examined. This paper offers a unique analysis of disaggregated prison admissions and investigates the spatial concentrations and levels of admissions for the entire state of Massachusetts.},
  langid = {english},
  keywords = {Incarceration,Neighborhoods,Poverty,Race and ethnicity,Spatial regression},
  file = {/home/work/Zotero/storage/IFPFHXBF/Simes - 2018 - Place and Punishment The Spatial Context of Mass .pdf}
}

@article{simesPolicingPunishmentPlace2023,
  title = {Policing, {{Punishment}}, and {{Place}}: {{Spatial-Contextual Analyses}} of the {{Criminal Legal System}}},
  shorttitle = {Policing, {{Punishment}}, and {{Place}}},
  author = {Simes, Jessica T. and Beck, Brenden and Eason, John M.},
  year = {2023},
  journal = {Annual Review of Sociology},
  volume = {49},
  number = {1},
  pages = {221--240},
  doi = {10.1146/annurev-soc-031021-035328},
  urldate = {2024-02-29},
  abstract = {Policing and punishment are unevenly distributed across geographic space. Research analyzing place-based variation in the criminal legal system is increasing, asking how community conditions contribute to variation in criminal justice outcomes and how multiple criminal justice exposures (e.g., policing and punishment) vary together in places. In this article, we identify spatial-contextual analyses of the criminal legal system and summarize their contributions by organizing them by their three major approaches: those emphasizing crime, urban ecology, or social control. We describe challenges the subfield faces, including an overemphasis on large cities and an overcommitment to analyzing criminal justice institutions like police or prisons discretely, when they are often experienced cumulatively and simultaneously. We call for research that transcends received institutional divisions, generates recommendations for stakeholders at multiple scales, makes greater use of formal spatial modeling, and analyzes places across the urban-rural continuum.},
  file = {/home/work/Zotero/storage/KFWC3Z89/Simes et al. - 2023 - Policing, Punishment, and Place Spatial-Contextua.pdf}
}

@book{simesPunishingPlacesGeography2021,
  title = {Punishing {{Places}}: {{The Geography}} of {{Mass Imprisonment}}},
  author = {Simes, Jessica T},
  year = {2021},
  publisher = {Univ of California Press}
}

@article{skardhamarDoesMarriageReduce2015,
  title = {Does {{Marriage Reduce Crime}}?},
  author = {Skardhamar, Torbj{\o}rn and Savolainen, Jukka and Aase, Kjersti N. and Lyngstad, Torkild H.},
  year = {2015},
  month = sep,
  journal = {Crime and Justice},
  volume = {44},
  pages = {385--446},
  publisher = {The University of Chicago Press},
  issn = {0192-3234},
  doi = {10.1086/681557},
  urldate = {2024-08-02},
  abstract = {The ``marriage effect'' is one of the most widely studied topics of life course criminology. The contemporary consensus is that marriage promotes desistance from crime. Most of the 58 studies reviewed here find a negative longitudinal association between marriage and crime. The results are more consistent among men. Studies that attend to relationship quality, such as the level of marital attachment, tend to produce particularly strong associations. Critical scrutiny of the evidence regarding the causal nature of the reported associations suggests, however, that claims about the restraining influence of marriage are overstated. None of the studies demonstrates evidence of direct (counterfactual) causality; no study has served a causal estimate unbiased by selection processes. Moreover, only a few studies address time ordering, and some of those show that desistance precedes rather than follows marriage. Evidence in support of the theoretical mechanisms responsible for the marriage effect is also mixed and insufficient. The criminological literature has been insensitive to the reality that entering a marital union is increasingly unlikely to signify the point at which a committed, high-quality relationship is formed.}
}

@article{spiegelhalterFunnelPlotsComparing2005,
  title = {Funnel Plots for Comparing Institutional Performance},
  author = {Spiegelhalter, David J.},
  year = {2005},
  month = apr,
  journal = {Statistics in Medicine},
  volume = {24},
  number = {8},
  pages = {1185--1202},
  issn = {0277-6715},
  doi = {10.1002/sim.1970},
  abstract = {'Funnel plots' are recommended as a graphical aid for institutional comparisons, in which an estimate of an underlying quantity is plotted against an interpretable measure of its precision. 'Control limits' form a funnel around the target outcome, in a close analogy to standard Shewhart control charts. Examples are given for comparing proportions and changes in rates, assessing association between outcome and volume of cases, and dealing with over-dispersion due to unmeasured risk factors. We conclude that funnel plots are flexible, attractively simple, and avoid spurious ranking of institutions into 'league tables'.},
  langid = {english},
  pmid = {15568194},
  keywords = {Adolescent,Biometry,Cardiac Surgical Procedures,Coronary Artery Bypass,Cross-Sectional Studies,England,Female,Humans,Infant,Odds Ratio,Outcome Assessment Health Care,Pregnancy,Pregnancy in Adolescence,Quality Assurance Health Care,Risk Factors}
}

@article{vanderweeleSensitivityAnalysisObservational2017,
  title = {Sensitivity {{Analysis}} in {{Observational Research}}: {{Introducing}} the {{E-Value}}},
  shorttitle = {Sensitivity {{Analysis}} in {{Observational Research}}},
  author = {VanderWeele, Tyler J. and Ding, Peng},
  year = {2017},
  month = aug,
  journal = {Annals of Internal Medicine},
  volume = {167},
  number = {4},
  pages = {268--274},
  publisher = {American College of Physicians},
  issn = {0003-4819},
  doi = {10.7326/M16-2607},
  urldate = {2024-07-08},
  abstract = {Sensitivity analysis is useful in assessing how robust an association is to potential unmeasured or uncontrolled confounding. This article introduces a new measure called the ``E-value,'' which is related to the evidence for causality in observational studies that are potentially subject to confounding. The E-value is defined as the minimum strength of association, on the risk ratio scale, that an unmeasured confounder would need to have with both the treatment and the outcome to fully explain away a specific treatment--outcome association, conditional on the measured covariates. A large E-value implies that considerable unmeasured confounding would be needed to explain away an effect estimate. A small E-value implies little unmeasured confounding would be needed to explain away an effect estimate. The authors propose that in all observational studies intended to produce evidence for causality, the E-value be reported or some other sensitivity analysis be used. They suggest calculating the E-value for both the observed association estimate (after adjustments for measured confounders) and the limit of the confidence interval closest to the null. If this were to become standard practice, the ability of the scientific community to assess evidence from observational studies would improve considerably, and ultimately, science would be strengthened.},
  file = {/home/work/Zotero/storage/44544VAS/VanderWeele and Ding - 2017 - Sensitivity Analysis in Observational Research In.pdf}
}

@article{verhoefQuasiPoissonVsNegative2007,
  title = {Quasi-{{Poisson}} vs. Negative Binomial Regression: How Should We Model Overdispersed Count Data?},
  shorttitle = {Quasi-{{Poisson}} vs. Negative Binomial Regression},
  author = {Ver Hoef, Jay M. and Boveng, Peter L.},
  year = {2007},
  month = nov,
  journal = {Ecology},
  volume = {88},
  number = {11},
  pages = {2766--2772},
  issn = {0012-9658},
  doi = {10.1890/07-0043.1},
  abstract = {Quasi-Poisson and negative binomial regression models have equal numbers of parameters, and either could be used for overdispersed count data. While they often give similar results, there can be striking differences in estimating the effects of covariates. We explain when and why such differences occur. The variance of a quasi-Poisson model is a linear function of the mean while the variance of a negative binomial model is a quadratic function of the mean. These variance relationships affect the weights in the iteratively weighted least-squares algorithm of fitting models to data. Because the variance is a function of the mean, large and small counts get weighted differently in quasi-Poisson and negative binomial regression. We provide an example using harbor seal counts from aerial surveys. These counts are affected by date, time of day, and time relative to low tide. We present results on a data set that showed a dramatic difference on estimating abundance of harbor seals when using quasi-Poisson vs. negative binomial regression. This difference is described and explained in light of the different weighting used in each regression method. A general understanding of weighting can help ecologists choose between these two methods.},
  langid = {english},
  pmid = {18051645},
  keywords = {Animals,Binomial Distribution,Data Collection,Data Interpretation Statistical,Linear Models,Models Statistical,Phoca,Poisson Distribution,Population Density,Population Growth,Probability,Regression Analysis,Seasons,Time Factors},
  file = {/home/work/Zotero/storage/A76GKNBU/Ver Hoef and Boveng - 2007 - Quasi-Poisson vs. negative binomial regression ho.pdf}
}

@incollection{verlaan2024use,
  title = {On the Use of Inferential Statistics on Administrative Police Data},
  booktitle = {The Crime Data Handbook},
  author = {Verlaan, Tim and Langton, Samuel},
  year = {2024},
  pages = {197--210},
  publisher = {Bristol University Press}
}

@article{walbyViolentCrimeIncreasing2016c,
  title = {Is {{Violent Crime Increasing}} or {{Decreasing}}? A {{New Methodology}} to {{Measure Repeat Attacks Making Visible}} the {{Significance}} of {{Gender}} and {{Domestic Relations}}},
  shorttitle = {Is {{Violent Crime Increasing}} or {{Decreasing}}?},
  author = {Walby, Sylvia and Towers, Jude and Francis, Brian},
  year = {2016},
  month = nov,
  journal = {The British Journal of Criminology},
  volume = {56},
  number = {6},
  pages = {1203--1234},
  issn = {0007-0955},
  doi = {10.1093/bjc/azv131},
  urldate = {2024-07-15},
  abstract = {The fall in the rate of violent crime has stopped. This is a finding of an investigation using the Crime Survey for England and Wales, 1994--2014, and an improved methodology to include the experiences of high-frequency victims. The cap on the number of crimes included has been removed. We prevent overall volatility from rising by using three-year moving averages and regression techniques that take account of all the data points rather than point to point analysis. The difference between our findings and official statistics is driven by violent crime committed against women and by domestic perpetrators. The timing of the turning point in the trajectory of violent crime corresponds with the economic crisis in 2008/09.},
  file = {/home/work/Zotero/storage/JKRFA3XA/Walby et al. - 2016 - Is Violent Crime Increasing or Decreasing a New M.pdf;/home/work/Zotero/storage/IEIP6NDB/2415172.html}
}
